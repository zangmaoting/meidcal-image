# -*- coding: utf-8 -*-
"""BraTs_data_creat.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IFlFG-4xGgnTIycGHqMCXSz_3BaNlAw-

Data dealing
"""

from google.colab import drive
drive.mount('/content/drive')

import os

folder_path = '/content/drive/MyDrive/CSC8639_folder'  # 替换成你想要的文件夹路径
os.makedirs(folder_path, exist_ok=True)

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/CSC8639_folder
!ls

from importlib.resources import path
import os
import nibabel as nib
import random
from PIL import Image

from glob import glob
import sys
import matplotlib.colors as colors
import matplotlib.pyplot as plt
import numpy as np
import nibabel as nib
from nibabel.testing import data_path

# importing packages for visualisation
import time
from ipywidgets import interact, interactive, IntSlider, ToggleButtons
from sklearn.model_selection import train_test_split

bratshgg_path = "/content/drive/MyDrive/CSC8639_folder/archive/MICCAI_BraTS_2018_Data_Training/HGG"
bratslgg_path = "/content/drive/MyDrive/CSC8639_folder/archive/MICCAI_BraTS_2018_Data_Training/LGG"

image_1_flair_gz = os.path.join(bratshgg_path + '/Brats18_2013_2_1/Brats18_2013_2_1_flair.nii')
image_1_t1_gz = os.path.join(bratshgg_path + '/Brats18_2013_2_1/Brats18_2013_2_1_t1.nii')
image_1_t1ce_gz = os.path.join(bratshgg_path + '/Brats18_2013_2_1/Brats18_2013_2_1_t1ce.nii')
image_1_t2_gz = os.path.join(bratshgg_path + '/Brats18_2013_2_1/Brats18_2013_2_1_t2.nii')
image_1_mask_gz = os.path.join(bratshgg_path + '/Brats18_2013_2_1/Brats18_2013_2_1_seg.nii')
# accessing the first volume and its modalities
image_1_flair = nib.load(image_1_flair_gz).get_fdata()
image_1_t1 = nib.load(image_1_t1_gz).get_fdata()
image_1_t1ce = nib.load(image_1_t1ce_gz).get_fdata()
image_1_t2 = nib.load(image_1_t2_gz).get_fdata()
image_1_mask = nib.load(image_1_mask_gz).get_fdata()
# loading the first volume and its modalities
# transforming to np array

image_1_flair.shape
# looking at the shape (240x240 pixels), 155 frames

print(nib.load(image_1_flair_gz))

fig, axs = plt.subplots(1,5, figsize=(30,30))
axs[0].imshow(image_1_mask[:,:,108], cmap='gray')
axs[0].set_title("Ground Truth", size ='xx-large')
axs[0].axis("off")
axs[1].imshow(image_1_flair[:,:,108], cmap='gray')
axs[1].set_title("FLAIR MRI Slice", size ='xx-large')
axs[1].axis("off")
axs[2].imshow(image_1_t1[:,:,108], cmap='gray')
axs[2].set_title("T1 MRI Slice", size ='xx-large')
axs[2].axis("off")
axs[3].imshow(image_1_t1ce[:,:,108], cmap='gray')
axs[3].set_title("T1-Gd MRI Slice", size ='xx-large')
axs[3].axis("off")
axs[4].imshow(image_1_t2[:,:,108], cmap='gray')
axs[4].set_title("T2 MRI Slice", size ='xx-large')
axs[4].axis("off")
plt.show()

image_1_label = os.path.join(bratshgg_path + '/Brats18_2013_2_1/Brats18_2013_2_1_seg.nii')
# accessing the label for the first training image
image_1_label = nib.load(image_1_label)
image_1_label.shape

print(image_1_label)

image_1_label_data = image_1_label.get_fdata()
# transforming to np array - don't need to use np.asarray necessarily

image_1_label_data.shape

plt.figure(figsize=(5,5))
plt.imshow(image_1_label_data[:,:,108], cmap='gray')
# plotting the label of the 1st training image - 108th frame shows clearly the tumour and pixels 0, 1, 2, 4 represents background, non-enhancing tumour, edema and enhancing tumour classes respectively
plt.colorbar();

image_1 = os.path.join(bratshgg_path + '/Brats18_2013_2_1/Brats18_2013_2_1_flair.nii')
# accessing the first flair volume
image_1 = nib.load(image_1)
# loading the flair volume
image_1_data = image_1.get_fdata()
# converting to np array

height, width, depth = image_1_data.shape
# getting the dimensions
print(f'This image has : \nHeight = {height}\nWidth = {width}\nDepth = {depth}')

# Function enabling interaction of all MRI layers
def visualisation(layer):
    plt.figure(figsize=(5,5))
    channel = 0
    plt.imshow(image_1_data[:,:, layer], cmap='gray')
    plt.title('Visualisation of Layers of Brain MRI', fontsize=20)
    plt.axis('off')
    return layer

interact(visualisation, layer = (0, image_1_data.shape[2]-1))

## Doing the same as above for the labels
image_1_label = os.path.join(bratshgg_path + '/Brats18_2013_2_1/Brats18_2013_2_1_seg.nii')
# accessing the label for the first training image
image_1_label = nib.load(image_1_label)
# loading the label for the first training image
image_1_label_data = image_1_label.get_fdata()

height, width, depth = image_1_label_data.shape
# getting the dimensions
print(f'This image has the following dimensions: \nHeight = {height}\nWidth = {width}\nDepth = {depth}.')
print(f'With the unique values: {np.unique(image_1_label_data)}.')
print('''Corresponding to the label categories:
 0: for background,
 1: for non-enhancing tumour,
 2: for edema
 4: for enhancing tumour''')
 # outlining the labels

classes = {
    'Background' : 0.,
    'Non-enhancing Tumour' : 1.,
    'Edema' : 2.,
    'Enhancing Tumour' : 4.,
}
select_class = ToggleButtons(
    options = ['Background','Non-enhancing Tumour', 'Edema', 'Enhancing Tumour'],
    description = 'Select Class:',
    disabled = False,
    button_style = 'info',

)
select_layer = IntSlider(min=0, max=154, description='Select Layer', continuous_update=False)

def plot_image(seg_class, layer):
    print(f"Plotting {layer} Layer Label: {seg_class}")
    img_label = classes[seg_class]
    mask = np.where(image_1_label_data[:,:, layer] == img_label, 255, 0)
    plt.figure(figsize=(10,5))
    plt.imshow(mask, cmap='gray')
    plt.axis('off');
# interactive jupyter widget to show different class labels
interactive(plot_image, seg_class = select_class, layer = select_layer)
# remember the white space represents the class that is being shown

image_original = os.path.join(bratshgg_path + '/Brats18_2013_2_1/Brats18_2013_2_1_t2.nii')
image_original = nib.load(image_original)
image_original = image_original.get_fdata()
img_preprocessed = np.load('data\\all_data\\img\\Brats18_2013_2_1_108.npy')

def extract_images_from_slices(frames_range, save_folder, seed = 0):
    root_dir = "/content/drive/MyDrive/CSC8639_folder/archive/MICCAI_BraTS_2018_Data_Training/LGG"
    flair = list()
    t1 = list()
    t2 = list()
    mask = list()

    for dirpath in os.listdir(root_dir):
        if os.path.isdir(os.path.join(root_dir,dirpath)):
            for filename in os.listdir(os.path.join(root_dir,dirpath)):
                if filename.endswith('_flair.nii'): flair.append(os.path.join(os.path.join(root_dir,dirpath,filename)))
                if filename.endswith('_t1ce.nii'): t1.append(os.path.join(os.path.join(root_dir,dirpath,filename)))
                if filename.endswith('_t2.nii'): t2.append(os.path.join(os.path.join(root_dir,dirpath,filename)))
                if filename.endswith('_seg.nii'): mask.append(os.path.join(os.path.join(root_dir,dirpath,filename)))



    all_indices = set(np.arange(len(flair)))
    random.seed(seed)  #every time set the same seed
    test_ratio = 0.2
    test_indices = random.sample(all_indices, int(test_ratio*len(all_indices)))
    train_indices = np.setdiff1d(list(all_indices), test_indices)
    np.random.seed(seed)
    np.random.shuffle(train_indices)
    train_indices = sorted(train_indices)
    random.seed(seed)  #every time set the same seed
    val_ratio = 0.2
    val_indices = random.sample(train_indices, int(val_ratio*len(train_indices)))
    train_indices = np.setdiff1d(list(train_indices), val_indices)

    save_frames(frames_range, save_folder,flair, t1, t2, mask, train_indices, split_type= "train")
    save_frames(frames_range, save_folder,flair, t1, t2, mask, test_indices, split_type= "test")
    save_frames(frames_range, save_folder,flair, t1, t2, mask, val_indices, split_type="val")

def filter_frame(mask):
    cls, counts = np.unique(mask, return_counts=True)
    satisfy = False
    for cl, cn in zip(cls,counts):
        if (cl == 1) or (cl == 2) or (cl == 4):
            if cn > 1000:
                satisfy = True
    return satisfy

def save_frames(frames_range, save_folder, flair, t1, t2, mask, indices, split_type = "train"):
    all_images_flair = list()
    all_t1_flair = list()
    all_t2_flair = list()
    all_mask_flair = list()

    flair_list = [f for i, f in enumerate(flair) if i in indices]
    t1_list = [t1_ for i, t1_ in enumerate(t1) if i in indices]
    t2_list = [t2_ for i, t2_ in enumerate(t2) if i in indices]
    mask_list = [m for i, m in enumerate(mask) if i in indices]


    for indx in range(len(flair_list)):
        flair_img=nib.load(flair_list[indx]).get_fdata()
        t1_img=nib.load(t1_list[indx]).get_fdata()
        t2_img=nib.load(t2_list[indx]).get_fdata()
        mask_img=nib.load(mask_list[indx]).get_fdata()

        for frame in range(frames_range[0], frames_range[1]):

            mask_slice = mask_img[:,:,frame]

            if filter_frame(mask_slice):
                flair_slice = flair_img[:,:,frame]
                t1_slice = t1_img[:,:,frame]
                t2_slice = t2_img[:,:,frame]

                os.makedirs(os.path.join(save_folder,"train"), exist_ok= True)
                os.makedirs(os.path.join(save_folder,"test"), exist_ok= True)
                os.makedirs(os.path.join(save_folder,"val"), exist_ok= True)

                all_images_flair.append(flair_slice)
                all_t1_flair.append(t1_slice)
                all_t2_flair.append(t2_slice)
                all_mask_flair.append(mask_slice)


    all_images_flair = np.array(all_images_flair)
    all_t1_flair = np.array(all_t1_flair)
    all_t2_flair = np.array(all_t2_flair)
    all_mask_flair = np.array(all_mask_flair).astype(np.uint8)

    print (all_images_flair.shape)

    np.save(os.path.join(save_folder,split_type,"flair_seed0_LGG.npy"), arr= all_images_flair)
    np.save(os.path.join(save_folder,split_type,"t1_seed0_LGG.npy"), arr= all_t1_flair)
    np.save(os.path.join(save_folder,split_type,"t2_seed0_LGG.npy"), arr= all_t2_flair)
    np.save(os.path.join(save_folder,split_type,"mask_seed0_LGG.npy"), arr= all_mask_flair)
    np.save(os.path.join(save_folder,split_type,"flair_seed0_HGG.npy"), arr= all_images_flair)
    np.save(os.path.join(save_folder,split_type,"t1_seed0_HGG.npy"), arr= all_t1_flair)
    np.save(os.path.join(save_folder,split_type,"t2_seed0_HGG.npy"), arr= all_t2_flair)
    np.save(os.path.join(save_folder,split_type,"mask_seed0_HGG.npy"), arr= all_mask_flair)

extract_images_from_slices(frames_range=(0,155), save_folder= "/content/drive/MyDrive/CSC8639_folder/data/BraTS_frames/MIUA")

import numpy as np
train = np.load("/content/drive/MyDrive/CSC8639_folder/data/BraTS_frames/MIUA/train/flair_seed0_HGG.npy")
val = np.load("/content/drive/MyDrive/CSC8639_folder/data/BraTS_frames/MIUA/val/flair_seed0_HGG.npy")
test = np.load("/content/drive/MyDrive/CSC8639_folder/data/BraTS_frames/MIUA/test/flair_seed0_HGG.npy")
print (train.shape,val.shape,test.shape)

import os
import numpy as np
from numpy import asarray, dtype
import torch
from torchvision import datasets, transforms
from torch.utils.data import Dataset, DataLoader
import torchvision
from collections import namedtuple
import numpy
import PIL.Image as Image
import math
import random
import pdb
from torchvision.transforms import functional as F
from torchvision.transforms.functional import InterpolationMode, _interpolation_modes_from_int


class BraTSDataset(Dataset):


    def __init__(self, root_dir, split_dir="/content/drive/MyDrive/CSC8639_folder/data/BraTS_frames/MIUA/train", flip=False, resize = None, scale= None, crop=None, version = 1, brightness = False, \
                  v_flip = False, rotation = False, random_crop = False, segmentation_type = "whole_tumor"):

        self.flip = flip
        self.scale = scale
        self.resize = resize
        self.crop = crop
        self.root_dir = root_dir
        self.rotation = rotation
        self.v_flip = v_flip
        self.brightness = brightness

        self.random_crop = random_crop
        self.split_dir = split_dir
        self.flair_dir = 'flair'
        self.t1_dir = 't1'
        self.mask_dir = 'mask'
        self.segmentation_type = segmentation_type



        if version == 5:
            self.flair_files = numpy.load(self.root_dir+split_dir+'flair_seed0_HGG.npy', allow_pickle='TRUE')
            self.t1_files = numpy.load(self.root_dir+split_dir+'t1_seed0_HGG.npy', allow_pickle='TRUE')
            self.mask_files = numpy.load(self.root_dir+split_dir+'mask_seed0_HGG.npy', allow_pickle='TRUE')

        elif version == 6:
            self.flair_files = numpy.load(self.root_dir+split_dir+'flair_seed0_LGG.npy', allow_pickle='TRUE')
            self.t1_files = numpy.load(self.root_dir+split_dir+'t1_seed0_LGG.npy', allow_pickle='TRUE')
            self.mask_files = numpy.load(self.root_dir+split_dir+'mask_seed0_LGG.npy', allow_pickle='TRUE')

        elif version == 7:

            self.flair_files = numpy.load(self.root_dir+split_dir+'flair_seed0_HGG.npy', allow_pickle='TRUE')
            self.t1_files = numpy.load(self.root_dir+split_dir+'t1_seed0_HGG.npy', allow_pickle='TRUE')
            self.mask_files = numpy.load(self.root_dir+split_dir+'mask_seed0_HGG.npy', allow_pickle='TRUE')

            ### concat HGG and LGG
            self.flair_files = np.concatenate((self.flair_files,numpy.load(self.root_dir+split_dir+'flair_seed0_LGG.npy', allow_pickle='TRUE')))
            self.t1_files = np.concatenate((self.t1_files,numpy.load(self.root_dir+split_dir+'t1_seed0_LGG.npy', allow_pickle='TRUE')))
            self.mask_files = np.concatenate((self.mask_files,numpy.load(self.root_dir+split_dir+'mask_seed0_LGG.npy', allow_pickle='TRUE')))


    def __len__(self):
        return len(self.flair_files)

    def slice_normalize(self,slice):
        '''
            input: unnormalized slice
            OUTPUT: normalized clipped slice
        '''

        # make sure that percentile below 1% and above 99% are cutoff
        b = np.percentile(slice, 99)
        t = np.percentile(slice, 1)
        slice = np.clip(slice, t, b)

        return slice

    def __getitem__(self, idx):

        flair_image = self.flair_files[idx]
        t1_image = self.t1_files[idx]


        flair_image = self.slice_normalize(flair_image)
        t1_image = self.slice_normalize(t1_image)

        flair_image = (torch.tensor(flair_image, dtype = torch.float32)).unsqueeze(0)
        t1_image = (torch.tensor(t1_image, dtype = torch.float32)).unsqueeze(0)
        mask = (torch.tensor(self.mask_files[idx])).unsqueeze(0)

        # ### make sure you dont go out of index, there is no class 3. so we are replacing 4 with 3
        # mask[mask==4] = 2
        # mask[mask == 2] = 2

        if self.segmentation_type == "whole_tumor":
            ### make sure that we have only one class
            # replace 3 with 1
            mask[mask==4] = 1
            mask[mask == 2] = 1

        if self.segmentation_type == "core_tumor":
            ### make sure that we have only one class
            mask[mask==4] = 1
            mask[mask==2] = 0

        if self.segmentation_type == "ET":
            ### make sure that we have only one class
            mask[mask==1] = 0
            mask[mask==2] = 0
            mask[mask==4] = 1


        flair_image, mask, t1_image = preprocess(flair_image, mask, t1_image, flip= self.flip, resize= self.resize, crop= self.crop, rotation = self.rotation, v_flip =self.v_flip, brightness = self.brightness, random_crop= self.random_crop)

        # flair_image = (flair_image/flair_image.max())
        # t1_image =  (t1_image/t1_image.max())

        flair_image = (flair_image - flair_image.min())/(flair_image.max() - flair_image.min())
        t1_image =  (t1_image - t1_image.min())/(t1_image.max()-t1_image.min())



        # # normalize the image to 0 mean and 1 std
        # flair_image = (flair_image - 0.110038705)/0.20635846
        # t1_image = (t1_image - 0.0982156)/0.17687258

        #broast cast all images to 3 channel
        # flair_image = flair_image.repeat(3,1,1)
        # t1_image = t1_image.repeat(3,1,1)

        return flair_image, mask.squeeze(0), t1_image


def preprocess(flair, mask, t1,  flip=False, resize = None, crop=None, rotation = False, v_flip = False, brightness = False, random_crop = False):


    if crop:
        flair = F.center_crop(flair,crop)
        t1 = F.center_crop(t1,crop)
        mask = F.center_crop(mask,crop)


    if resize:
        previous = len(np.unique(mask))
        flair = F.resize(flair, size= resize, interpolation =InterpolationMode.BILINEAR, antialias = True)
        t1 = F.resize(t1, size= resize, interpolation =InterpolationMode.BILINEAR, antialias = True)
        mask = F.resize(mask, size= resize, interpolation =InterpolationMode.NEAREST, antialias = False)


    if random_crop:

        _,h,w = mask.shape

        if random.random() < 0.5:
            new_size = random.uniform(h-40,h-10)
            flair = F.center_crop(flair,new_size)
            t1 = F.center_crop(t1,new_size)
            mask = F.center_crop(mask,new_size)

        # make sure to resize back to the original size
        flair = F.resize(flair, size= (h,w), interpolation =InterpolationMode.BILINEAR, antialias = True)
        t1 = F.resize(t1, size= (h,w), interpolation =InterpolationMode.BILINEAR, antialias = True)
        mask = F.resize(mask, size= (h,w), interpolation =InterpolationMode.NEAREST, antialias = False)



    if flip:
        if random.random() < 0.5:
            flair = F.hflip(flair)
            t1 = F.hflip(t1)
            mask =F.hflip(mask)

    if v_flip:
        if random.random() < 0.5:
            flair = F.vflip(flair)
            t1 = F.vflip(t1)
            mask =F.vflip(mask)

    if rotation:
        if random.random() < 0.5:
            degree = random.uniform(-20,20)
            flair = F.rotate(flair, degree, interpolation = InterpolationMode.BILINEAR, fill = 0.)
            t1 = F.rotate(t1, degree, interpolation = InterpolationMode.BILINEAR, fill = 0.)
            mask = F.rotate(mask, degree, interpolation = InterpolationMode.NEAREST, fill = 0.)

    # if brightness:
    #     brightness_factor = random.uniform(0.9,1.1)
    #     flair = F.adjust_brightness(flair, brightness_factor)
    #     t1 = F.adjust_brightness(t1, brightness_factor)

    # if shear:
    #     if random.random() < 0.5:
    #         shear_degree = random.uniform(-10,10)
    #         flair = F.affine(flair, angle =0, translate = (0,0), interpolation = InterpolationMode.BILINEAR)
    #         t1 = F.affine(t1, degree, interpolation = InterpolationMode.BILINEAR)
    #         mask = F.affine(mask, degree, interpolation = InterpolationMode.NEAREST)

    mask = mask.long()
    return flair, mask, t1

dataset = BraTSDataset("/content/drive/MyDrive/CSC8639_folder/data/BraTS_frames/MIUA", flip = False, split_dir ="/train/", resize= 0, \
                           crop = 0, version= 5,v_flip = False, brightness = False, rotation = False, random_crop= False)
def compute_mean(data):

    mean = np.mean(data)
    std = np.std(data)

    print ("mean: ", mean, "std :",std, "max: ",np.max(data), "min: ", np.min(data))

t1s = []
flairs = []

for i, (flair, m, t1) in enumerate(dataset):
    flairs.append(flair.numpy())
    t1s.append(t1.numpy())


t1s = np.array(t1s)
flairs = np.array(flairs)

compute_mean(flairs)
compute_mean(t1s)

data = numpy.load("/content/drive/MyDrive/CSC8639_folder/data/BraTS_frames/MIUA/val/"+'mask_seed0_HGG.npy', allow_pickle='TRUE')
classes = {2:0,3:0,4:0}
for d in data:
    no_classes = len(numpy.unique(d))
    classes[no_classes] = classes[no_classes]+1

print (classes)

import matplotlib
import matplotlib.pyplot as plt
matplotlib.rcParams.update({'font.size':12})
plt.figure(figsize=(8,5))
plt.bar(classes.keys(),classes.values(), width = 0.3)
plt.ylabel("Counts")
plt.xlabel("Classes")

flairs = []
classes = []
t1s = []
masks = []

train_dataset = BraTSDataset("/content/drive/MyDrive/CSC8639_folder/data/BraTS_frames/MIUA/", flip = True, split_dir ="train/", resize= 0, \
                             crop = 0, version= 5,v_flip = True, brightness = True, rotation = True, random_crop= True)
for i, (flair, m, t1) in enumerate(train_dataset):
    flairs.append(flair)
    t1s.append(t1)
    masks.append(m)

f1 = np.array(flairs[0]).flatten()
for f in flairs:
    np.concatenate((f1, np.array(f).flatten()))

import matplotlib.pyplot as plt
fig, ax = plt.subplots(figsize=(5, 5))
print (type(f1))
plt.hist(f1[f1 !=0.], bins = 200)

plt.show()

import matplotlib.pyplot as plt

num_rows = 5  # 可根据数据集大小进行调整
num_columns = 3
f, axarr = plt.subplots(num_rows, num_columns, figsize=(10, 10))
cnt = 0

for i in range(0, len(flairs), len(flairs) // num_rows):
    if cnt >= num_rows:
        break

    adjust_i = cnt
    cnt += 1

    d1 = axarr[adjust_i, 0].imshow(flairs[i].squeeze(0), cmap="gray")
    axarr[adjust_i, 0].set_title("flairs")
    plt.colorbar(d1, ax=axarr[adjust_i, 0])

    d2 = axarr[adjust_i, 1].imshow(masks[i], cmap="gray")
    axarr[adjust_i, 1].set_title("mask")
    plt.colorbar(d2, ax=axarr[adjust_i, 1])

    d3 = axarr[adjust_i, 2].imshow(t1s[i].squeeze(0), cmap="gray")
    axarr[adjust_i, 2].set_title("t1")
    plt.colorbar(d3, ax=axarr[adjust_i, 2])

plt.tight_layout()
plt.show()

import os
import torch
from torch.utils.data import Dataset, DataLoader
import numpy as np

def classification_labels(mask, classes=[1, 2, 4]):
    one_hot_labels = torch.zeros(len(classes), dtype=torch.double)

    for i, k in enumerate(classes):
        if k in mask:
            one_hot_labels[int(i)] = 1
    return one_hot_labels

def BraTSDataset_save_classification(root_dir, split_dir="train/", version=1):

    classes = []

    if version == 5:
        mask_files = numpy.load(os.path.join(root_dir, split_dir, 'mask_seed0_HGG.npy'), allow_pickle=True)
    elif version == 6:
        mask_files = numpy.load(os.path.join(root_dir, split_dir, 'mask_seed0_LGG.npy'), allow_pickle=True)

    for mask in mask_files:
        classes.append(classification_labels(mask))

    classes = np.array(classes)

    if version == 5:
        np.save(os.path.join(root_dir, split_dir, "multilabel_classes_seed0_HGG.npy"), arr=classes)
    elif version == 6:
        np.save(os.path.join(root_dir, split_dir, "multilabel_classes_seed0_LGG.npy"), arr=classes)

os.getcwd()

root_dir = "/content/drive/MyDrive/CSC8639_folder/data/BraTS_frames/MIUA"
BraTSDataset_save_classification(root_dir, split_dir="/content/drive/MyDrive/CSC8639_folder/data/BraTS_frames/MIUA/train", version=5)
BraTSDataset_save_classification(root_dir, split_dir="/content/drive/MyDrive/CSC8639_folder/data/BraTS_frames/MIUA/test", version=5)
BraTSDataset_save_classification(root_dir, split_dir="/content/drive/MyDrive/CSC8639_folder/data/BraTS_frames/MIUA/val", version=5)
BraTSDataset_save_classification(root_dir, split_dir="/content/drive/MyDrive/CSC8639_folder/data/BraTS_frames/MIUA/train", version=6)
BraTSDataset_save_classification(root_dir, split_dir="/content/drive/MyDrive/CSC8639_folder/data/BraTS_frames/MIUA/test", version=6)
BraTSDataset_save_classification(root_dir, split_dir="/content/drive/MyDrive/CSC8639_folder/data/BraTS_frames/MIUA/val", version=6)

data = np.load('/content/drive/MyDrive/CSC8639_folder/data/BraTS_frames/MIUA/test/multilabel_classes_seed0_HGG.npy', allow_pickle = True)

from logging import raiseExceptions
import os
import numpy as np
from numpy import asarray, dtype
import torch
from torchvision import datasets, transforms
from torch.utils.data import Dataset, DataLoader
import torchvision
from collections import namedtuple
import numpy
import PIL.Image as Image
import math
import random
import pdb
from torchvision.transforms import functional as F
from torchvision.transforms.functional import InterpolationMode, _interpolation_modes_from_int

class BraTSDataset(Dataset):


    def __init__(self, root_dir, train = True, flip=False, resize = None, scale= None, crop=None):

        self.flip = flip
        self.scale = scale
        self.resize = resize
        self.crop = crop
        self.root_dir = root_dir

        if train:
            split_dir = "/content/drive/MyDrive/CSC8639_folder/data/BraTS_frames/MIUA/train"
        else:
            split_dir = "/content/drive/MyDrive/CSC8639_folder/data/BraTS_frames/MIUA/test"

        self.flair_files = numpy.load(os.path.join(self.root_dir,split_dir,'flair_multilabel.npy'), allow_pickle='TRUE')
        self.t1_files = numpy.load(os.path.join(self.root_dir,split_dir,'t1_multilabel.npy'), allow_pickle='TRUE')
        self.class_files = numpy.load(os.path.join(self.root_dir,split_dir,'classes_multilabel.npy'), allow_pickle='TRUE')
        self.mask_files = numpy.load(os.path.join(self.root_dir,split_dir,'mask_multilabel.npy'), allow_pickle='TRUE')



    def __len__(self):
        return len(self.flair_files)

    def __getitem__(self, idx):

        flair_image = (torch.tensor(self.flair_files[idx], dtype = torch.float32))
        t1_image = (torch.tensor(self.t1_files[idx], dtype = torch.float32))
        classes = (torch.tensor(self.class_files[idx]))
        mask = (torch.tensor(self.mask_files[idx])).unsqueeze(0)

        # print(np.unique(mask),classes)


        flair_image, mask, t1_image = preprocess(flair_image, mask, t1_image, flip= self.flip, resize= self.resize, crop= self.crop)
        # print (flair_image.shape)

        return flair_image/2000, classes, t1_image/2000, mask


def preprocess(flair, mask, t1,  flip=False, resize = None, crop=None):


    if resize:
        previous = len(np.unique(mask))
        flair = F.resize(flair, size= resize, interpolation =InterpolationMode.BILINEAR, antialias = True)
        t1 = F.resize(t1, size= resize, interpolation =InterpolationMode.BILINEAR, antialias = True)
        mask = F.resize(mask, size= resize, interpolation =InterpolationMode.NEAREST, antialias = False)
        if len(np.unique(mask)) != previous:
            print ("The classes has been changed due to downsampling")
            # raise NotImplementedError

    if crop:
        flair = F.center_crop(flair,crop)
        t1 = F.center_crop(t1,crop)
        mask = F.center_crop(mask,crop)


    if flip:
        if random.random() < 0.5:
            flair = F.hflipe(flair)
            t1 = F.hflip(t1)
            mask =F.hflip(mask)

    mask = mask.long()

    return flair, mask, t1